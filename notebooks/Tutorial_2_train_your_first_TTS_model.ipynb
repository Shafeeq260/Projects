{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f79d99ef",
      "metadata": {
        "id": "f79d99ef"
      },
      "source": [
        "# Train your first 🐸 TTS model 💫\n",
        "\n",
        "### 👋 Hello and welcome to Coqui (🐸) TTS\n",
        "\n",
        "The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with 🐸.\n",
        "\n",
        "Let's train a very small model on a very small amount of data so we can iterate quickly.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Download data and format it for 🐸 TTS.\n",
        "2. Configure the training and testing runs.\n",
        "3. Train a new model.\n",
        "4. Test the model and display its performance.\n",
        "\n",
        "So, let's jump right in!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fa2aec78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa2aec78",
        "outputId": "448a1562-d7e1-465a-a720-6b62d951f55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.15.3)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.3)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.15)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (25.0)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.1)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.9.post2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.10.0)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from TTS) (0.54.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.5)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.53.2)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.4.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.8.7)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->TTS) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.8.1->TTS) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp>=3.8.1->TTS) (4.14.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core>=20211220 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (20250515)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.18.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.33.0->TTS) (1.1.5)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "## Install Coqui TTS\n",
        "! pip install -U pip\n",
        "! pip install TTS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5fe49c",
      "metadata": {
        "id": "be5fe49c"
      },
      "source": [
        "## ✅ Data Preparation\n",
        "\n",
        "### **First things first**: we need some data.\n",
        "\n",
        "We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [🐸TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n",
        "\n",
        "If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n",
        "\n",
        "The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/wavs<br />\n",
        " &emsp;| - audio1.wav<br />\n",
        " &emsp;| - audio2.wav<br />\n",
        " &emsp;| - audio3.wav<br />\n",
        "  ...<br />\n",
        "</span>\n",
        "\n",
        "and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "# metadata.csv <br />\n",
        "audio1|This is my sentence. <br />\n",
        "audio2|This is maybe my sentence. <br />\n",
        "audio3|This is certainly my sentence. <br />\n",
        "audio4|Let this be your sentence. <br />\n",
        "...\n",
        "</span>\n",
        "\n",
        "In the end, we should have the following **folder structure**:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/MyTTSDataset <br />\n",
        "&emsp;| <br />\n",
        "&emsp;| -> metadata.csv<br />\n",
        "&emsp;| -> /wavs<br />\n",
        "&emsp;&emsp;| -> audio1.wav<br />\n",
        "&emsp;&emsp;| -> audio2.wav<br />\n",
        "&emsp;&emsp;| ...<br />\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69501a10-3b53-4e75-ae66-90221d6f2271",
      "metadata": {
        "id": "69501a10-3b53-4e75-ae66-90221d6f2271"
      },
      "source": [
        "🐸TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. <br />\n",
        "\n",
        "After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. <br /> The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n",
        "\n",
        "If you use a different dataset format then the LJSpeech or the other public datasets that 🐸TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f226c8-4e55-48fa-937b-8415d539b17c",
      "metadata": {
        "id": "e7f226c8-4e55-48fa-937b-8415d539b17c"
      },
      "source": [
        "## ⏳️ Loading your dataset\n",
        "Load one of the dataset supported by 🐸TTS.\n",
        "\n",
        "We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
        "outputId": "d73f502c-558e-472e-8c31-bfc57308b7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Uploading MyTTSDataset ===\n",
            "Please select your MyTTSDataset.zip file from:\n",
            "C:\\Users\\shafe\\OneDrive\\shafeeq\\Saras AI\\Project- TTS- voice cloning\\MyTTSDataset.zip\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "print(\"=== Uploading MyTTSDataset ===\")\n",
        "print(\"Please select your MyTTSDataset.zip file from:\")\n",
        "print(\"C:\\\\Users\\\\shafe\\\\OneDrive\\\\shafeeq\\\\Saras AI\\\\Project- TTS- voice cloning\\\\MyTTSDataset.zip\")\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
        "outputId": "5d33b86b-bb79-4260-ab8f-0968294d30c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-17 18:24:30--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 195.181.163.196, 2400:52e0:1a02::1210:1\n",
            "Connecting to data.keithito.com (data.keithito.com)|195.181.163.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [text/plain]\n",
            "Saving to: ‘/content/LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "/content/LJSpeech-1 100%[===================>]   2.56G   190MB/s    in 30s     \n",
            "\n",
            "2025-07-17 18:25:00 (87.9 MB/s) - ‘/content/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Download and extract LJSpeech dataset.\n",
        "output_path = \"/content\"\n",
        "!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5",
      "metadata": {
        "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5"
      },
      "outputs": [],
      "source": [
        "from TTS.config import BaseDatasetConfig\n",
        "\n",
        "# Now define your dataset configuration\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    meta_file_train=\"metadata.csv\",\n",
        "    path=\"/content/LJSpeech-1.1/\" # Updated path to the extracted dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae82fd75",
      "metadata": {
        "id": "ae82fd75"
      },
      "source": [
        "## ✅ Train a new model\n",
        "\n",
        "Let's kick off a training run 🚀🚀🚀.\n",
        "\n",
        "Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n",
        "We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f",
      "metadata": {
        "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f"
      },
      "source": [
        "We will begin by initializing the model training configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
      "metadata": {
        "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "\n",
        "# --- Make sure these variables are defined first ---\n",
        "\n",
        "# 1. Define the output path for your training run\n",
        "output_path = \"glow_tts_training_run\"\n",
        "\n",
        "# 2. Make sure `dataset_config` is defined from a previous cell\n",
        "# Example:\n",
        "# dataset_config = {\n",
        "#     \"name\": \"ljspeech\",\n",
        "#     \"meta_file_train\": \"metadata.csv\",\n",
        "#     \"path\": \"/content/MyTTSDataset/\"\n",
        "# }\n",
        "\n",
        "\n",
        "# --- Now, create the model training configuration ---\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=100,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    # Corrected path joining\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    # Use the variable defined above\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93ed377-80b7-447b-bd92-106bffa777ee",
      "metadata": {
        "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
      },
      "source": [
        "Next we will initialize the audio processor which is used for feature extraction and audio I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
        "outputId": "75e86229-bd5a-4ddb-ea5c-d7f9224c74a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "# Modify sample rate if for a custom audio dataset:\n",
        "# ap.sample_rate = 22050\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d461683-b05e-403f-815f-8007bda08c38",
      "metadata": {
        "id": "1d461683-b05e-403f-815f-8007bda08c38"
      },
      "source": [
        "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
      "metadata": {
        "id": "014879b7-f18d-44c0-b24a-e10f8002113a"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978",
      "metadata": {
        "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
      },
      "source": [
        "Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
        "outputId": "fe0247d1-606a-410e-a5d8-2b9572ebfc7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 13100 files in /content/LJSpeech-1.1\n"
          ]
        }
      ],
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19",
      "metadata": {
        "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
      },
      "source": [
        "Now we're ready to initialize the model.\n",
        "\n",
        "Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4",
      "metadata": {
        "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.models.glow_tts import GlowTTS\n",
        "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2832c56-889d-49a6-95b6-eb231892ecc6",
      "metadata": {
        "id": "e2832c56-889d-49a6-95b6-eb231892ecc6"
      },
      "source": [
        "Trainer provides a generic API to train all the 🐸TTS models with all its perks like mixed-precision training, distributed training, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
        "outputId": "3ecac2b0-9ba4-47f4-cf42-9e9ce831144b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 13100 files in /content/LJSpeech-1.1\n"
          ]
        }
      ],
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "\n",
        "# Load the training and evaluation samples from your dataset_config\n",
        "# This returns two lists of file paths and text\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,  # Use the corrected dataset_config\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b320831-dd83-429b-bb6a-473f9d49d321",
      "metadata": {
        "id": "5b320831-dd83-429b-bb6a-473f9d49d321"
      },
      "source": [
        "### AND... 3,2,1... START TRAINING 🚀🚀🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
        "outputId": "e08bec88-8201-4754-e244-b24d4fa6ddbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: True\n",
            " | > Precision: fp16\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=glow_tts_training_run/run-July-17-2025_06+45PM-0000000\n",
            "[!] Small Run, only using 0 samples.\n",
            "\n",
            " > Model has 28610257 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
            " --> glow_tts_training_run/run-July-17-2025_06+45PM-0000000\n",
            " ! Run is removed from glow_tts_training_run/run-July-17-2025_06+45PM-0000000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1833, in fit\n",
            "    self._fit()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1785, in _fit\n",
            "    self.train_epoch()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1483, in train_epoch\n",
            "    self.train_loader = self.get_train_dataloader(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 949, in get_train_dataloader\n",
            "    return self._get_loader(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 909, in _get_loader\n",
            "    loader = model.get_data_loader(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/TTS/tts/models/base_tts.py\", line 346, in get_data_loader\n",
            "    dataset.preprocess_samples()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/TTS/tts/datasets/dataset.py\", line 368, in preprocess_samples\n",
            "    raise RuntimeError(\" [!] No samples left\")\n",
            "RuntimeError:  [!] No samples left\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1833, in fit\n",
            "    self._fit()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1785, in _fit\n",
            "    self.train_epoch()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1483, in train_epoch\n",
            "    self.train_loader = self.get_train_dataloader(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 949, in get_train_dataloader\n",
            "    return self._get_loader(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 909, in _get_loader\n",
            "    loader = model.get_data_loader(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/TTS/tts/models/base_tts.py\", line 346, in get_data_loader\n",
            "    dataset.preprocess_samples()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/TTS/tts/datasets/dataset.py\", line 368, in preprocess_samples\n",
            "    raise RuntimeError(\" [!] No samples left\")\n",
            "RuntimeError:  [!] No samples left\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-57-1195939795.py\", line 40, in <cell line: 0>\n",
            "    trainer.fit()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\", line 1862, in fit\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1833\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1784\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_train_epoch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_with_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1785\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1483\u001b[0;31m             self.train_loader = self.get_train_dataloader(\n\u001b[0m\u001b[1;32m   1484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_assets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mget_train_dataloader\u001b[0;34m(self, training_assets, samples, verbose)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         return self._get_loader(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_get_loader\u001b[0;34m(self, model, config, assets, is_eval, samples, verbose, num_gpus)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misimplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_data_loader\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                 loader = model.get_data_loader(\n\u001b[0m\u001b[1;32m    910\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_gpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/models/base_tts.py\u001b[0m in \u001b[0;36mget_data_loader\u001b[0;34m(self, config, assets, is_eval, samples, verbose, num_gpus, rank)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;31m# sort input sequences from short to long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/datasets/dataset.py\u001b[0m in \u001b[0;36mpreprocess_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" [!] No samples left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m:  [!] No samples left",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-57-1195939795.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "from trainer import Trainer\n",
        "import torch\n",
        "\n",
        "# Create a dummy args object with necessary attributes\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.restore_path = None\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.output_path = config.output_path\n",
        "        self.config = config  # Add config to args\n",
        "        self.config_path = None # Add config_path if needed by Trainer\n",
        "        self.dataset_path = None # Add dataset_path if needed by Trainer\n",
        "        self.continue_path = None # Add continue_path if needed by Trainer\n",
        "        self.grad_accum_steps = 1 # Add grad_accum_steps attribute\n",
        "        self.overfit_batch = False # Add overfit_batch attribute as seen in help(Trainer) example usage\n",
        "        self.skip_train_epoch = False # Add skip_train_epoch attribute as seen in help(Trainer) example usage\n",
        "        self.start_with_eval = False # Add start_with_eval attribute\n",
        "        self.rank = 0 # Add rank attribute for single-process logging\n",
        "        self.use_ddp = False # Add use_ddp attribute\n",
        "        self.gpu = None # Add gpu attribute\n",
        "        self.use_accelerate = False # Add use_accelerate attribute\n",
        "        self.small_run = False # Add small_run attribute\n",
        "\n",
        "\n",
        "args = Args()\n",
        "\n",
        "\n",
        "# Initialize the trainer\n",
        "trainer = Trainer(\n",
        "    args, # First positional argument\n",
        "    config, # Second positional argument\n",
        "    config.output_path, # Third positional argument\n",
        "    model=model, # Keyword argument\n",
        "    parse_command_line_args=False, # Disable command-line argument parsing\n",
        "    train_samples=train_samples, # Pass training samples\n",
        "    eval_samples=eval_samples, # Pass evaluation samples\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98",
      "metadata": {
        "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98"
      },
      "source": [
        "#### 🚀 Run the Tensorboard. 🚀\n",
        "On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
        "outputId": "2566ad91-95c3-4c34-8a5b-a581694ff2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "2025-07-17 18:48:40.239269: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752778120.276806   30517 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752778120.284818   30517 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-17 18:48:46.760245: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard\n",
        "!tensorboard --logdir=tts_train_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f6dc959",
      "metadata": {
        "id": "9f6dc959"
      },
      "source": [
        "## ✅ Test the model\n",
        "\n",
        "We made it! 🙌\n",
        "\n",
        "Let's kick off the testing run, which displays performance metrics.\n",
        "\n",
        "We're committing the cardinal sin of ML 😈 (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable 😇\n",
        "\n",
        "You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n",
        "\n",
        "When you start training your own models, make sure your testing data doesn't include your training data 😅"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0",
      "metadata": {
        "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0"
      },
      "source": [
        "Let's get the latest saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961",
      "metadata": {
        "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "output_path = \"tts_train_dir\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd42bc7a",
      "metadata": {
        "id": "dd42bc7a"
      },
      "outputs": [],
      "source": [
        " !tts --text \"Text for TTS\" \\\n",
        "      --model_path $test_ckpt \\\n",
        "      --config_path $test_config \\\n",
        "      --out_path out.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670",
      "metadata": {
        "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670"
      },
      "source": [
        "## 📣 Listen to the synthesized wave 📣"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
      "metadata": {
        "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13914401-cad1-494a-b701-474e52829138",
      "metadata": {
        "id": "13914401-cad1-494a-b701-474e52829138"
      },
      "source": [
        "## 🎉 Congratulations! 🎉 You now have trained your first TTS model!\n",
        "Follow up with the next tutorials to learn more advanced material."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7",
      "metadata": {
        "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba6d105b",
        "outputId": "d0a7504a-e586-42bc-80f3-8a1c56d69277"
      },
      "source": [
        "from trainer import Trainer\n",
        "\n",
        "# Get the help information for the Trainer class\n",
        "help(Trainer)\n",
        "\n",
        "# Alternatively, you can try to inspect the constructor\n",
        "# print(Trainer.__init__.__doc__)\n",
        "# print(Trainer.__init__.__code__.co_varnames)"
      ],
      "id": "ba6d105b",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Trainer in module trainer.trainer:\n",
            "\n",
            "class Trainer(builtins.object)\n",
            " |  Trainer(args: trainer.trainer.TrainerArgs, config: coqpit.coqpit.Coqpit, output_path: str, c_logger: trainer.logging.console_logger.ConsoleLogger = None, dashboard_logger: 'Logger' = None, model: torch.nn.modules.module.Module = None, get_model: Callable = None, get_data_samples: Callable = None, train_samples: List = None, eval_samples: List = None, test_samples: List = None, train_loader: torch.utils.data.dataloader.DataLoader = None, eval_loader: torch.utils.data.dataloader.DataLoader = None, training_assets: Dict = {}, parse_command_line_args: bool = True, callbacks: Dict[str, Callable] = {}, gpu: int = None) -> None\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, args: trainer.trainer.TrainerArgs, config: coqpit.coqpit.Coqpit, output_path: str, c_logger: trainer.logging.console_logger.ConsoleLogger = None, dashboard_logger: 'Logger' = None, model: torch.nn.modules.module.Module = None, get_model: Callable = None, get_data_samples: Callable = None, train_samples: List = None, eval_samples: List = None, test_samples: List = None, train_loader: torch.utils.data.dataloader.DataLoader = None, eval_loader: torch.utils.data.dataloader.DataLoader = None, training_assets: Dict = {}, parse_command_line_args: bool = True, callbacks: Dict[str, Callable] = {}, gpu: int = None) -> None\n",
            " |      Simple yet powerful 🐸💬 TTS trainer for PyTorch. It can train all the available `tts` and `vocoder` models\n",
            " |      or easily be customized.\n",
            " |      \n",
            " |      Notes:\n",
            " |      \n",
            " |          Supports Automatic Mixed Precision training. If `Apex` is availabe, it automatically picks that, else\n",
            " |          it uses PyTorch's native `amp` module. `Apex` may provide more stable training in some cases.\n",
            " |      \n",
            " |      Args:\n",
            " |      \n",
            " |          args (Union[Coqpit, Namespace]): Training arguments parsed either from console by `argparse` or `TrainerArgs`\n",
            " |              config object.\n",
            " |      \n",
            " |          config (Coqpit): Model config object. It includes all the values necessary for initializing, training, evaluating\n",
            " |              and testing the model.\n",
            " |      \n",
            " |          output_path (str): Path to the output training folder. All the files are saved under thi path.\n",
            " |      \n",
            " |          c_logger (ConsoleLogger, optional): Console logger for printing training status. If not provided, the default\n",
            " |              console logger is used. Defaults to None.\n",
            " |      \n",
            " |          dashboard_logger Union[TensorboardLogger, WandbLogger]: Dashboard logger. If not provided, the tensorboard logger is used.\n",
            " |              Defaults to None.\n",
            " |      \n",
            " |          model (nn.Module, optional): Initialized and ready-to-train model. If it is not defined, `Trainer`\n",
            " |              initializes a model from the provided config. Defaults to None.\n",
            " |      \n",
            " |          get_model (Callable):\n",
            " |              A function that returns a model. It is used to initialize the model when `model` is not provided.\n",
            " |              It either takes the config as the only argument or does not take any argument.\n",
            " |              Defaults to None\n",
            " |      \n",
            " |          get_data_samples (Callable):\n",
            " |              A function that returns a list of training and evaluation samples. Used if `train_samples` and\n",
            " |              `eval_samples` are None. Defaults to None.\n",
            " |      \n",
            " |          train_samples (List):\n",
            " |              A list of training samples used by the model's `get_train_data_loader` to init the `dataset` and the\n",
            " |              `data_loader`. Defaults to None.\n",
            " |      \n",
            " |          eval_samples (List):\n",
            " |              A list of evaluation samples used by the model's `get_eval_data_loader` to init the `dataset` and the\n",
            " |              `data_loader`. Defaults to None.\n",
            " |      \n",
            " |          train_loader (DataLoader):\n",
            " |              A pytorch data loader object for training epochs. Leave as None if you want it to be made during training. Defaults to None.\n",
            " |      \n",
            " |          eval_loader (DataLoader):\n",
            " |              A pytorch data loader object for evaluation epochs. Leave as None to be generated during training. Defaults to None.\n",
            " |      \n",
            " |          test_samples (List):\n",
            " |              A list of test samples used by the model's `get_test_data_loader` to init the `dataset` and the\n",
            " |              `data_loader`. If None, the ```model.test_run()``` is expected to load the data. Defaults to None.\n",
            " |      \n",
            " |          training_assets (Dict):\n",
            " |              A dictionary of assets to be used at training and passed to the model's ```train_log(), eval_log(), get_data_loader()```\n",
            " |              during training. It can include  `AudioProcessor` or/and `Tokenizer`. Defaults to {}.\n",
            " |      \n",
            " |          parse_command_line_args (bool):\n",
            " |              If true, parse command-line arguments and update `TrainerArgs` and model `config` values. Set it\n",
            " |              to false if you parse the arguments yourself. Defaults to True.\n",
            " |      \n",
            " |          callbacks (Dict[str, Callable]):\n",
            " |              A dictionary of callbacks to be used during training. The keys are the callback names and the values\n",
            " |      \n",
            " |          gpu (int):\n",
            " |              GPU ID to use for training If \"CUDA_VISIBLE_DEVICES\" is not set. Defaults to None.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          Running trainer with a model.\n",
            " |      \n",
            " |          >>> args = TrainerArgs(...)\n",
            " |          >>> config = ModelConfig(...)\n",
            " |          >>> model = Model(config)\n",
            " |          >>> trainer = Trainer(args, config, output_path, model=model)\n",
            " |          >>> trainer.fit()\n",
            " |      \n",
            " |          TODO:\n",
            " |              - Wrap model for not calling .module in DDP.\n",
            " |              - Deepspeed integration\n",
            " |              - Profiler integration.\n",
            " |              - Overfitting to a batch.\n",
            " |              - TPU training\n",
            " |  \n",
            " |  detach_loss_dict(self, loss_dict: Dict, step_optimizer: bool, optimizer_idx: int = None, grad_norm: float = None)\n",
            " |  \n",
            " |  eval_epoch(self) -> None\n",
            " |      Main entry point for the evaluation loop. Run evaluation on the all validation samples.\n",
            " |  \n",
            " |  eval_step(self, batch: Dict, step: int) -> Tuple[Dict, Dict]\n",
            " |      Perform a evaluation step on a batch of inputs and log the process.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch (Dict): Input batch.\n",
            " |          step (int): Current step number in this epoch.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tuple[Dict, Dict]: Model outputs and losses.\n",
            " |  \n",
            " |  fit(self) -> None\n",
            " |      Where the ✨️magic✨️ happens...\n",
            " |  \n",
            " |  fit_with_largest_batch_size(self, starting_batch_size=2048) -> None\n",
            " |  \n",
            " |  format_batch(self, batch: List) -> Dict\n",
            " |      Format the dataloader output and return a batch.\n",
            " |      \n",
            " |      1. Call ```model.format_batch```.\n",
            " |      2. Pass the batch to the Device.\n",
            " |      3. Call ```model.format_batch_on_device```.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch (List): Batch returned by the dataloader.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Dict: Formatted batch.\n",
            " |  \n",
            " |  get_eval_dataloader(self, training_assets: Dict, samples: List, verbose: bool) -> torch.utils.data.dataloader.DataLoader\n",
            " |      Initialize and return a evaluation data loader.\n",
            " |      Call ```model.get_eval_data_loader``` if it is implemented, else call ```model.get_data_loader```\n",
            " |      and set ```is_eval=True```.\n",
            " |      \n",
            " |      Args:\n",
            " |          ap (AudioProcessor): Audio processor.\n",
            " |          samples (List): Data samples used for training.\n",
            " |          verbose (bool): enable/disable printing loader stats at initialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          DataLoader: Initialized training data loader.\n",
            " |  \n",
            " |  get_test_dataloader(self, training_assets: Dict, samples: List, verbose: bool) -> torch.utils.data.dataloader.DataLoader\n",
            " |      Initialize and return a evaluation data loader.\n",
            " |      Call ```model.get_test_data_loader``` if it is implemented, else call ```model.get_data_loader```\n",
            " |      and set ```is_eval=True```.\n",
            " |      \n",
            " |      Args:\n",
            " |          ap (AudioProcessor): Audio processor.\n",
            " |          samples (List): Data samples used for training.\n",
            " |          verbose (bool): enable/disable printing loader stats at initialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          DataLoader: Initialized training data loader.\n",
            " |  \n",
            " |  get_train_dataloader(self, training_assets: Dict, samples: List, verbose: bool) -> torch.utils.data.dataloader.DataLoader\n",
            " |      Initialize and return a training data loader.\n",
            " |      Call ```model.get_train_data_loader``` if it is implemented, else call ```model.get_data_loader```\n",
            " |      and set ```is_eval=False```.\n",
            " |      \n",
            " |      Args:\n",
            " |          ap (AudioProcessor): Audio processor.\n",
            " |          samples (List): Data samples used for training.\n",
            " |          verbose (bool): enable/disable printing loader stats at initialization.\n",
            " |      \n",
            " |      Returns:\n",
            " |          DataLoader: Initialized training data loader.\n",
            " |  \n",
            " |  optimize(self, batch: Dict, model: torch.nn.modules.module.Module, optimizer: torch.optim.optimizer.Optimizer, scaler: 'AMPScaler', criterion: torch.nn.modules.module.Module, scheduler: Union[torch.optim.lr_scheduler._LRScheduler, List, Dict], config: coqpit.coqpit.Coqpit, optimizer_idx: int = None, step_optimizer: bool = True, num_optimizers: int = 1) -> Tuple[Dict, Dict, int]\n",
            " |      Perform a forward - backward pass and run the optimizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch (Dict): Input batch. If\n",
            " |          model (nn.Module): Model for training. Defaults to None.\n",
            " |          optimizer (Union[nn.optim.Optimizer, List]): Model's optimizer. If it is a list then, `optimizer_idx` must be defined to indicate the optimizer in use.\n",
            " |          scaler (AMPScaler): AMP scaler.\n",
            " |          criterion (nn.Module): Model's criterion.\n",
            " |          scheduler (torch.optim.lr_scheduler._LRScheduler): LR scheduler used by the optimizer.\n",
            " |          config (Coqpit): Model config.\n",
            " |          optimizer_idx (int, optional): Target optimizer being used. Defaults to None.\n",
            " |          step_optimizer (bool, optional): Whether step the optimizer. If False, gradients are accumulated and\n",
            " |              model parameters are not updated. Defaults to True.\n",
            " |          num_optimizers (int, optional): Number of optimizers. Defaults to 1.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: When the loss is NaN.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tuple[Dict, Dict, int, torch.Tensor]: model outputs, losses, step time and gradient norm.\n",
            " |  \n",
            " |  prepare_accelerate_loader(self, data_loader)\n",
            " |      Prepare the accelerator for the training.\n",
            " |  \n",
            " |  profile_fit(self, torch_profiler, epochs=None, small_run=None)\n",
            " |      Run training under the torch profiler.\n",
            " |      \n",
            " |      Example::\n",
            " |          Run torch profiler to profile CPU, GPU and memory usage with Tensorboard logging.\n",
            " |      \n",
            " |          >>> import torch\n",
            " |          >>> profiler = torch.profiler.profile(\n",
            " |          >>>        activities=[\n",
            " |          >>>         torch.profiler.ProfilerActivity.CPU,\n",
            " |          >>>         torch.profiler.ProfilerActivity.CUDA,\n",
            " |          >>>     ],\n",
            " |          >>>     schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
            " |          >>>     on_trace_ready=torch.profiler.tensorboard_trace_handler(\"./profiler/\"),\n",
            " |          >>>     record_shapes=True,\n",
            " |          >>>     profile_memory=True,\n",
            " |          >>>     with_stack=True,\n",
            " |          >>> )\n",
            " |          >>> prof = trainer.profile_fit(profiler, epochs=1, small_run=64)\n",
            " |  \n",
            " |  restore_lr(self, config, args, model, optimizer)\n",
            " |  \n",
            " |  restore_model(self, config: coqpit.coqpit.Coqpit, restore_path: str, model: torch.nn.modules.module.Module, optimizer: torch.optim.optimizer.Optimizer, scaler: torch.cuda.amp.grad_scaler.GradScaler = None) -> Tuple[torch.nn.modules.module.Module, torch.optim.optimizer.Optimizer, torch.cuda.amp.grad_scaler.GradScaler, int]\n",
            " |      Restore training from an old run. It restores model, optimizer, AMP scaler and training stats.\n",
            " |      \n",
            " |      Args:\n",
            " |          config (Coqpit): Model config.\n",
            " |          restore_path (str): Path to the restored training run.\n",
            " |          model (nn.Module): Model to restored.\n",
            " |          optimizer (torch.optim.Optimizer): Optimizer to restore.\n",
            " |          scaler (torch.cuda.amp.GradScaler, optional): AMP scaler to restore. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tuple[nn.Module, torch.optim.Optimizer, torch.cuda.amp.GradScaler, int]: [description]\n",
            " |  \n",
            " |  save_best_model(self) -> None\n",
            " |      Save the best model. It only saves if the current target loss is smaller then the previous.\n",
            " |  \n",
            " |  save_checkpoint(self) -> None\n",
            " |      Save the current model checkpoint.\n",
            " |  \n",
            " |  save_training_script(self)\n",
            " |      Save the training script to tracking dashboard and output path.\n",
            " |  \n",
            " |  setup_accelerate(self)\n",
            " |  \n",
            " |  setup_small_run(self, small_run: int = None)\n",
            " |      Use a subset of samples for training, evaluation and testing.\n",
            " |  \n",
            " |  test(self, model=None, test_samples=None) -> None\n",
            " |      Run evaluation steps on the test data split. You can either provide the model and the test samples\n",
            " |      explicitly or the trainer use values from the initialization.\n",
            " |      \n",
            " |      Args:\n",
            " |          model (nn.Module, optional): Model to use for testing. If None, use the model given in the initialization.\n",
            " |              Defaults to None.\n",
            " |      \n",
            " |          test_samples (List[str], optional): List of test samples to use for testing. If None, use the test samples\n",
            " |              given in the initialization. Defaults to None.\n",
            " |  \n",
            " |  test_run(self) -> None\n",
            " |      Run model test.\n",
            " |      \n",
            " |      Test run is expected to pass over test samples and produce logging artifacts.\n",
            " |      \n",
            " |      If ```model.test_run()``` is defined, it will be called and it is expected to set and execute everything\n",
            " |      in the model.\n",
            " |      \n",
            " |      Else if  ```mode.test()``` is defined, it will be called and it takes an test data loader as an argument\n",
            " |      and iterate over it.\n",
            " |  \n",
            " |  train_epoch(self) -> None\n",
            " |      Main entry point for the training loop. Run training on the all training samples.\n",
            " |  \n",
            " |  train_step(self, batch: Dict, batch_n_steps: int, step: int, loader_start_time: float) -> Tuple[Dict, Dict]\n",
            " |      Perform a training step on a batch of inputs and log the process.\n",
            " |      \n",
            " |      Args:\n",
            " |          batch (Dict): Input batch.\n",
            " |          batch_n_steps (int): Number of steps needed to complete an epoch. Needed for logging.\n",
            " |          step (int): Current step number in this epoch.\n",
            " |          loader_start_time (float): The time when the data loading is started. Needed for logging.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Tuple[Dict, Dict]: Model outputs and losses.\n",
            " |  \n",
            " |  update_training_dashboard_logger(self, batch=None, outputs=None)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  get_criterion(model: torch.nn.modules.module.Module) -> torch.nn.modules.module.Module\n",
            " |      Receive the criterion from the model. Model must implement `get_criterion()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          model (nn.Module): Training model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          nn.Module: Criterion layer.\n",
            " |  \n",
            " |  get_lr(model: torch.nn.modules.module.Module, config: coqpit.coqpit.Coqpit) -> Union[float, List[float]]\n",
            " |      Set the initial learning rate by the model if model implements `get_lr()` else try setting the learning rate\n",
            " |      fromthe config.\n",
            " |      \n",
            " |      Args:\n",
            " |          model (nn.Module): Training model.\n",
            " |          config (Coqpit): Training configuration.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Union[float, List[float]]: A single learning rate or a list of learning rates, one for each optimzier.\n",
            " |  \n",
            " |  get_optimizer(model: torch.nn.modules.module.Module, config: coqpit.coqpit.Coqpit) -> Union[torch.optim.optimizer.Optimizer, List]\n",
            " |      Receive the optimizer from the model if model implements `get_optimizer()` else\n",
            " |      check the optimizer parameters in the config and try initiating the optimizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          model (nn.Module): Training model.\n",
            " |          config (Coqpit): Training configuration.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Union[torch.optim.Optimizer, List]: A optimizer or a list of optimizers. GAN models define a list.\n",
            " |  \n",
            " |  get_scheduler(model: torch.nn.modules.module.Module, config: coqpit.coqpit.Coqpit, optimizer: Union[torch.optim.optimizer.Optimizer, List, Dict]) -> Union[torch.optim.lr_scheduler._LRScheduler, List]\n",
            " |      Receive the scheduler from the model if model implements `get_scheduler()` else\n",
            " |      check the config and try initiating the scheduler.\n",
            " |      \n",
            " |      Args:\n",
            " |          model (nn.Module): Training model.\n",
            " |          config (Coqpit): Training configuration.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Union[torch.optim.Optimizer, List, Dict]: A scheduler or a list of schedulers, one for each optimizer.\n",
            " |  \n",
            " |  init_accelerate(model, optimizer, training_dataloader, scheduler, grad_accum_steps, mixed_precision, precision)\n",
            " |      Setup HF Accelerate for the training.\n",
            " |  \n",
            " |  init_loggers(config: 'Coqpit', output_path: str, dashboard_logger=None, c_logger=None)\n",
            " |      Init console and dashboard loggers.\n",
            " |      Use the given logger if passed externally else use config values to pick the right logger.\n",
            " |      Return a dashboard logger only for the rank 0 process in DDP\n",
            " |      Define a console logger for each process in DDP\n",
            " |      \n",
            " |      Args:\n",
            " |          config (Coqpit): Model config.\n",
            " |          output_path (str): Output path to save the training artifacts.\n",
            " |          dashboard_logger (DashboardLogger): Object passed to the trainer from outside.\n",
            " |          c_logger (ConsoleLogger): Object passed to the trained from outside.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Initialized dashboard_logger and console_logger objects.\n",
            " |  \n",
            " |  init_training(args: trainer.trainer.TrainerArgs, coqpit_overrides: Dict, config: coqpit.coqpit.Coqpit = None)\n",
            " |      Initialize training and update model configs from command line arguments.\n",
            " |      \n",
            " |      Args:\n",
            " |          args (argparse.Namespace or dict like): Parsed trainer arguments.\n",
            " |          config_overrides (argparse.Namespace or dict like): Parsed config overriding arguments.\n",
            " |          config (Coqpit): Model config. If none, it is generated from `args`. Defaults to None.\n",
            " |      \n",
            " |      Returns:\n",
            " |          config (Coqpit): Config paramaters.\n",
            " |  \n",
            " |  master_params(optimizer: torch.optim.optimizer.Optimizer)\n",
            " |      Generator over parameters owned by the optimizer.\n",
            " |      \n",
            " |      Used to select parameters used by the optimizer for gradient clipping.\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: Target optimizer.\n",
            " |  \n",
            " |  parse_argv(args: Union[coqpit.coqpit.Coqpit, List])\n",
            " |      Parse command line arguments to init or override `TrainerArgs()`.\n",
            " |  \n",
            " |  restore_scheduler(scheduler: Union[ForwardRef('Scheduler'), List, Dict], args: coqpit.coqpit.Coqpit, config: coqpit.coqpit.Coqpit, restore_epoch: int, restore_step: int) -> Union[ForwardRef('Scheduler'), List]\n",
            " |      Restore scheduler wrt restored model.\n",
            " |  \n",
            " |  run_get_data_samples(config: coqpit.coqpit.Coqpit, get_data_samples: Callable) -> torch.nn.modules.module.Module\n",
            " |  \n",
            " |  run_get_model(config: coqpit.coqpit.Coqpit, get_model: Callable) -> torch.nn.modules.module.Module\n",
            " |      Run the `get_model` function and return the model.\n",
            " |      \n",
            " |      Args:\n",
            " |          config (Coqpit): Model config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          nn.Module: initialized model.\n",
            " |  \n",
            " |  setup_training_environment(args, config, gpu)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  use_accelerate\n",
            " |      Return True if using HF Accelerate.\n",
            " |  \n",
            " |  use_apex\n",
            " |      Return True if using APEX.\n",
            " |  \n",
            " |  use_pt_ddp\n",
            " |      Return True if using PyTorch DDP.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}