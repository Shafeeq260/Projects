{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shafeeq260/Projects/blob/main/Copy_of_Tutorial_2_train_your_first_TTS_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f79d99ef",
      "metadata": {
        "id": "f79d99ef"
      },
      "source": [
        "# Train your first üê∏ TTS model üí´\n",
        "\n",
        "### üëã Hello and welcome to Coqui (üê∏) TTS\n",
        "\n",
        "The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with üê∏.\n",
        "\n",
        "Let's train a very small model on a very small amount of data so we can iterate quickly.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Download data and format it for üê∏ TTS.\n",
        "2. Configure the training and testing runs.\n",
        "3. Train a new model.\n",
        "4. Test the model and display its performance.\n",
        "\n",
        "So, let's jump right in!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fa2aec78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa2aec78",
        "outputId": "59ed7745-36e0-4940-a857-b7d3f20398eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.1.1)\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.16.0)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.3)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2025.7.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.11.15)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (25.0)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.1)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.9.post2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.10.0)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from TTS) (0.55.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.5)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.53.2)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.4.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.8.7)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->TTS) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.8.1->TTS) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp>=3.8.1->TTS) (4.14.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.10.0->TTS) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core>=20211220 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (20250515)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.18.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=4.33.0->TTS) (1.1.5)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n"
          ]
        }
      ],
      "source": [
        "## Install Coqui TTS\n",
        "! pip install -U pip\n",
        "! pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ltFveP2Re5iT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltFveP2Re5iT",
        "outputId": "3f2e598c-b06d-49f7-a35e-86e53bb4a310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5fe49c",
      "metadata": {
        "id": "be5fe49c"
      },
      "source": [
        "## ‚úÖ Data Preparation\n",
        "\n",
        "### **First things first**: we need some data.\n",
        "\n",
        "We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [üê∏TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n",
        "\n",
        "If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n",
        "\n",
        "The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/wavs<br />\n",
        " &emsp;| - audio1.wav<br />\n",
        " &emsp;| - audio2.wav<br />\n",
        " &emsp;| - audio3.wav<br />\n",
        "  ...<br />\n",
        "</span>\n",
        "\n",
        "and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "# metadata.csv <br />\n",
        "audio1|This is my sentence. <br />\n",
        "audio2|This is maybe my sentence. <br />\n",
        "audio3|This is certainly my sentence. <br />\n",
        "audio4|Let this be your sentence. <br />\n",
        "...\n",
        "</span>\n",
        "\n",
        "In the end, we should have the following **folder structure**:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/MyTTSDataset <br />\n",
        "&emsp;| <br />\n",
        "&emsp;| -> metadata.csv<br />\n",
        "&emsp;| -> /wavs<br />\n",
        "&emsp;&emsp;| -> audio1.wav<br />\n",
        "&emsp;&emsp;| -> audio2.wav<br />\n",
        "&emsp;&emsp;| ...<br />\n",
        "</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69501a10-3b53-4e75-ae66-90221d6f2271",
      "metadata": {
        "id": "69501a10-3b53-4e75-ae66-90221d6f2271"
      },
      "source": [
        "üê∏TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. <br />\n",
        "\n",
        "After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. <br /> The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n",
        "\n",
        "If you use a different dataset format then the LJSpeech or the other public datasets that üê∏TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f226c8-4e55-48fa-937b-8415d539b17c",
      "metadata": {
        "id": "e7f226c8-4e55-48fa-937b-8415d539b17c"
      },
      "source": [
        "## ‚è≥Ô∏è Loading your dataset\n",
        "Load one of the dataset supported by üê∏TTS.\n",
        "\n",
        "We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66",
      "metadata": {
        "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the path to your dataset here\n",
        "dataset_path = \"/content/drive\"\n",
        "\n",
        "# The rest of your code\n",
        "output_path = \"tts_train_dir\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae6b7019-3685-4b48-8917-c152e288d7e3",
        "outputId": "9fbdec0e-3bb9-4b05-cfc9-651cf72aec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-25 09:23:40--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 143.244.50.83, 2400:52e0:1a01::900:1\n",
            "Connecting to data.keithito.com (data.keithito.com)|143.244.50.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [text/plain]\n",
            "Saving to: ‚Äòtts_train_dir/LJSpeech-1.1.tar.bz2‚Äô\n",
            "\n",
            "tts_train_dir/LJSpe 100%[===================>]   2.56G  47.4MB/s    in 33s     \n",
            "\n",
            "2025-07-25 09:24:13 (79.8 MB/s) - ‚Äòtts_train_dir/LJSpeech-1.1.tar.bz2‚Äô saved [2748572632/2748572632]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download and extract LJSpeech dataset.\n",
        "\n",
        "!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5",
      "metadata": {
        "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\",\n",
        "    meta_file_train=\"metadata.csv\",\n",
        "    path=\"tts_train_dir/LJSpeech-1.1\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae82fd75",
      "metadata": {
        "id": "ae82fd75"
      },
      "source": [
        "## ‚úÖ Train a new model\n",
        "\n",
        "Let's kick off a training run üöÄüöÄüöÄ.\n",
        "\n",
        "Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n",
        "We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f",
      "metadata": {
        "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f"
      },
      "source": [
        "We will begin by initializing the model training configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84",
      "metadata": {
        "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84"
      },
      "outputs": [],
      "source": [
        "# GlowTTSConfig: all model related values for training, validating and testing.\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=5,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93ed377-80b7-447b-bd92-106bffa777ee",
      "metadata": {
        "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
      },
      "source": [
        "Next we will initialize the audio processor which is used for feature extraction and audio I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
        "outputId": "3ee02260-b8c5-45f9-affc-72df9e29ee8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "# Modify sample rate if for a custom audio dataset:\n",
        "# ap.sample_rate = 22050\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d461683-b05e-403f-815f-8007bda08c38",
      "metadata": {
        "id": "1d461683-b05e-403f-815f-8007bda08c38"
      },
      "source": [
        "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "014879b7-f18d-44c0-b24a-e10f8002113a",
      "metadata": {
        "id": "014879b7-f18d-44c0-b24a-e10f8002113a"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978",
      "metadata": {
        "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
      },
      "source": [
        "Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
        "outputId": "bd54a298-df54-4207-a49e-d369c6f16294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping malformed row: [\"audio1.wav|Hello, my name is Muhammed Shafeeq and I'm creating a voice cloning dataset.\"]\n",
            "Skipping malformed row: ['audio4.wav|Technology has advanced rapidly in recent years, especially artificial intelligence.']\n",
            "Skipping malformed row: ['audio18.wav|Data science combines statistics, programming, and domain expertise effectively.']\n",
            "Loaded 17 samples.\n",
            "Train samples: 16\n",
            "Eval samples: 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "\n",
        "# Define the path to your dataset here - make sure this matches the path used in other cells\n",
        "# Assuming you have uploaded your dataset to Google Drive and it's in a folder named 'myTTSDataset'\n",
        "# directly under 'My Drive'. If not, adjust the path accordingly.\n",
        "dataset_path = \"/content/tts_train_dir/LJSpeech-1.1\"\n",
        "metadata_file = os.path.join(dataset_path, \"metadata.csv\")\n",
        "wavs_path = os.path.join(dataset_path, \"wavs\")\n",
        "\n",
        "# Manually load and format the data\n",
        "samples = []\n",
        "# Check if the metadata file exists before trying to open it\n",
        "if not os.path.exists(metadata_file):\n",
        "    print(f\"Error: metadata file not found at {metadata_file}\")\n",
        "else:\n",
        "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f, delimiter='|')\n",
        "        for row in reader:\n",
        "            # Assuming the format is audio_file_name|transcription\n",
        "            if len(row) >= 2:\n",
        "                audio_file_name = row[0].strip()\n",
        "                text = row[1].strip()\n",
        "                # Construct the full path to the audio file\n",
        "                # Ensure no extra quotes or duplicated extensions\n",
        "                full_audio_path = os.path.join(wavs_path, audio_file_name + \".wav\").replace('\"', '')\n",
        "                # Extract the base name without extension for audio_unique_name\n",
        "                audio_unique_name = os.path.splitext(audio_file_name)[0]\n",
        "                # Add the sample to the list, including audio_unique_name and language\n",
        "                # Use the language defined in the config (from cell ac2ffe3e-ad0c-443e-800c-9b076ee811b4)\n",
        "                language = \"en-us\" # This should match phoneme_language in your config\n",
        "                samples.append({\"text\": text, \"audio_file\": full_audio_path, \"speaker_name\": \"default\", \"audio_unique_name\": audio_unique_name, \"language\": language})\n",
        "            else:\n",
        "                print(f\"Skipping malformed row: {row}\")\n",
        "\n",
        "\n",
        "    # Split the samples into training and evaluation sets\n",
        "    if samples: # Only split if samples were loaded\n",
        "        train_samples, eval_samples = train_test_split(\n",
        "            samples,\n",
        "            test_size=0.05,  # At least 1 sample out of 20\n",
        "            random_state=42  # for reproducibility\n",
        "        )\n",
        "\n",
        "        # Print the number of samples loaded to verify\n",
        "        print(f\"Loaded {len(samples)} samples.\")\n",
        "        print(f\"Train samples: {len(train_samples)}\")\n",
        "        print(f\"Eval samples: {len(eval_samples)}\")\n",
        "    else:\n",
        "        train_samples = []\n",
        "        eval_samples = []\n",
        "        print(\"No samples loaded from metadata file.\")\n",
        "\n",
        "\n",
        "# The original code had incorrect replace calls and relied on the problematic load_tts_samples\n",
        "# We have replaced it with manual data loading and formatting to fix the IndexError and FileNotFoundError.\n",
        "# Ensure the dataset_path defined here matches the one used in the config initialization cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19",
      "metadata": {
        "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
      },
      "source": [
        "Now we're ready to initialize the model.\n",
        "\n",
        "Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4",
      "metadata": {
        "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b991c9-e590-4840-9621-e9a31f890816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "<function _ConnectionBase.__del__ at 0x7d1103ffa8e0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 133, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "Exception in thread QueueFeederThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "Exception in thread QueueFeederThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "Exception in thread QueueFeederThread:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 239, in _feed\n",
            "    reader_close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 178, in close\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 377, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
            "    queue_sem.release()\n",
            "ValueError: semaphore or lock released too many times\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
            "    queue_sem.release()\n",
            "ValueError: semaphore or lock released too many times\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 271, in _feed\n",
            "    queue_sem.release()\n",
            "ValueError: semaphore or lock released too many times\n"
          ]
        }
      ],
      "source": [
        "from TTS.tts.models.glow_tts import GlowTTS\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig # Import BaseDatasetConfig\n",
        "\n",
        "# Define dataset_path and output_path again to ensure they are available\n",
        "import os\n",
        "output_path = \"tts_train_dir\"\n",
        "# Update this path to your dataset location in Google Drive\n",
        "dataset_path = \"/content/drive/MyDrive/myTTSDataset/\" # Ensure correct dataset_path\n",
        "\n",
        "# Redefine dataset_config to ensure it is available\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=dataset_path\n",
        ")\n",
        "\n",
        "# Redefine config with GlowTTSConfig to ensure the correct configuration is used\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=0,  # Reduced number of workers\n",
        "    num_eval_loader_workers=0, # Reduced number of eval workers\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=5,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=False,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")\n",
        "\n",
        "# Initialize the GlowTTS model with the correct config\n",
        "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2832c56-889d-49a6-95b6-eb231892ecc6",
      "metadata": {
        "id": "e2832c56-889d-49a6-95b6-eb231892ecc6"
      },
      "source": [
        "Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training, distributed training, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
        "outputId": "83a7ab17-f2b1-436d-a889-142aa54c2433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: False\n",
            " | > Precision: float32\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            " > Model has 28610257 parameters\n"
          ]
        }
      ],
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "# Explicitly set the language key for each sample to ensure it's present\n",
        "language = \"en-us\" # This should match phoneme_language in your config\n",
        "for sample in train_samples:\n",
        "    sample['language'] = language\n",
        "for sample in eval_samples:\n",
        "    sample['language'] = language\n",
        "\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b320831-dd83-429b-bb6a-473f9d49d321",
      "metadata": {
        "id": "5b320831-dd83-429b-bb6a-473f9d49d321"
      },
      "source": [
        "### AND... 3,2,1... START TRAINING üöÄüöÄüöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
        "outputId": "9780f781-9573-4da5-a1e3-7f0b4cf7505f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/5\u001b[0m\n",
            " --> tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-07-25 10:07:49) \u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w äd ju la…™k t…ô dÕ° í…î…™n mi f…ö k…îfi √∞…™s √¶ft…önun?\n",
            " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2025-07-25 10:08:04 -- STEP: 0/1 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 10.6027  (10.602692127227783)\n",
            "     | > loader_time: 4.2207  (4.220726490020752)\n",
            "\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 64\n",
            " | > Min text length: 64\n",
            " | > Avg text length: 64.0\n",
            " | \n",
            " | > Max audio length: 311079.0\n",
            " | > Min audio length: 311079.0\n",
            " | > Avg audio length: 311079.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/TTS/tts/models/glow_tts.py:415: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):  # avoid mixed_precision in criterion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.48752498626708984 \u001b[0m(+0)\n",
            "     | > avg_loss: 8893436928.0 \u001b[0m(+0)\n",
            "     | > avg_log_mle: 8893436928.0 \u001b[0m(+0)\n",
            "     | > avg_loss_dur: 4.549579620361328 \u001b[0m(+0)\n",
            "\n",
            " > BEST MODEL : tts_train_dir/run-July-25-2025_10+04AM-0000000/best_model_1.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/5\u001b[0m\n",
            " --> tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-07-25 10:08:14) \u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/TTS/tts/models/glow_tts.py:415: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled=False):  # avoid mixed_precision in criterion\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.3417623043060303 \u001b[0m(-0.14576268196105957)\n",
            "     | > avg_loss: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 4.549579620361328 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/5\u001b[0m\n",
            " --> tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-07-25 10:08:32) \u001b[0m\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.3541584014892578 \u001b[0m(+0.012396097183227539)\n",
            "     | > avg_loss: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 4.549579620361328 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/5\u001b[0m\n",
            " --> tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-07-25 10:08:53) \u001b[0m\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5080325603485107 \u001b[0m(+0.15387415885925293)\n",
            "     | > avg_loss: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 4.549579620361328 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/5\u001b[0m\n",
            " --> tts_train_dir/run-July-25-2025_10+04AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2025-07-25 10:09:11) \u001b[0m\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.36446475982666016 \u001b[0m(-0.14356780052185059)\n",
            "     | > avg_loss: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 8893436928.0 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 4.549579620361328 \u001b[0m(+0.0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98",
      "metadata": {
        "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98"
      },
      "source": [
        "#### üöÄ Run the Tensorboard. üöÄ\n",
        "On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
      "metadata": {
        "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43955ce-d690-4cbf-c2e2-ea1ab10e5c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "2025-07-25 10:11:16.651672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753438276.677353   14745 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753438276.684789   14745 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-25 10:11:21.151976: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.18.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard\n",
        "!tensorboard --logdir=tts_train_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f6dc959",
      "metadata": {
        "id": "9f6dc959"
      },
      "source": [
        "## ‚úÖ Test the model\n",
        "\n",
        "We made it! üôå\n",
        "\n",
        "Let's kick off the testing run, which displays performance metrics.\n",
        "\n",
        "We're committing the cardinal sin of ML üòà (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable üòá\n",
        "\n",
        "You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n",
        "\n",
        "When you start training your own models, make sure your testing data doesn't include your training data üòÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0",
      "metadata": {
        "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0"
      },
      "source": [
        "Let's get the latest saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961",
      "metadata": {
        "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e990409-ce07-4826-c571-5f4ec9187333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint: tts_train_dir/run-July-25-2025_10+04AM-0000000/best_model_1.pth\n",
            "Latest config: \n"
          ]
        }
      ],
      "source": [
        "import glob, os\n",
        "output_path = \"tts_train_dir\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "# Modify glob pattern to also look for config.json directly in output_path\n",
        "configs = sorted(glob.glob(output_path + \"/**/*.json\", recursive=True))\n",
        "\n",
        "\n",
        "# Assign the latest checkpoint and config to variables\n",
        "test_ckpt = ckpts[-1] if ckpts else \"\"\n",
        "test_config = configs[-1] if configs else \"\"\n",
        "\n",
        "print(f\"Latest checkpoint: {test_ckpt}\")\n",
        "print(f\"Latest config: {test_config}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "dd42bc7a",
      "metadata": {
        "id": "dd42bc7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d0aa2f-aa15-4b3e-f5de-3da8fd7f5918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: tts [-h] [--list_models [LIST_MODELS]]\n",
            "           [--model_info_by_idx MODEL_INFO_BY_IDX]\n",
            "           [--model_info_by_name MODEL_INFO_BY_NAME] [--text TEXT]\n",
            "           [--model_name MODEL_NAME] [--vocoder_name VOCODER_NAME]\n",
            "           [--config_path CONFIG_PATH] [--model_path MODEL_PATH]\n",
            "           [--out_path OUT_PATH] [--use_cuda USE_CUDA] [--device DEVICE]\n",
            "           [--vocoder_path VOCODER_PATH]\n",
            "           [--vocoder_config_path VOCODER_CONFIG_PATH]\n",
            "           [--encoder_path ENCODER_PATH]\n",
            "           [--encoder_config_path ENCODER_CONFIG_PATH] [--pipe_out [PIPE_OUT]]\n",
            "           [--speakers_file_path SPEAKERS_FILE_PATH]\n",
            "           [--language_ids_file_path LANGUAGE_IDS_FILE_PATH]\n",
            "           [--speaker_idx SPEAKER_IDX] [--language_idx LANGUAGE_IDX]\n",
            "           [--speaker_wav SPEAKER_WAV [SPEAKER_WAV ...]]\n",
            "           [--gst_style GST_STYLE]\n",
            "           [--capacitron_style_wav CAPACITRON_STYLE_WAV]\n",
            "           [--capacitron_style_text CAPACITRON_STYLE_TEXT]\n",
            "           [--list_speaker_idxs [LIST_SPEAKER_IDXS]]\n",
            "           [--list_language_idxs [LIST_LANGUAGE_IDXS]]\n",
            "           [--save_spectogram SAVE_SPECTOGRAM] [--reference_wav REFERENCE_WAV]\n",
            "           [--reference_speaker_idx REFERENCE_SPEAKER_IDX]\n",
            "           [--progress_bar PROGRESS_BAR] [--source_wav SOURCE_WAV]\n",
            "           [--target_wav TARGET_WAV] [--voice_dir VOICE_DIR]\n",
            "tts: error: argument --config_path: expected one argument\n"
          ]
        }
      ],
      "source": [
        "!tts --text \"Text for TTS\" \\\n",
        "     --model_path $test_ckpt \\\n",
        "     --config_path $test_config \\\n",
        "     --out_path out.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670",
      "metadata": {
        "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670"
      },
      "source": [
        "## üì£ Listen to the synthesized wave üì£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
      "metadata": {
        "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d12148f5-59bc-44b4-c820-ece334b16dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current files: ['.config', 'tts_train_dir', 'drive', 'sample_data']\n",
            "File not found: out.wav\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Import display module\n",
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "# üìÇ Check files in current directory (optional)\n",
        "print(\"Current files:\", os.listdir())\n",
        "\n",
        "# üéß Play audio if available\n",
        "audio_path = \"out.wav\"  # Adjust if your file is inside a folder\n",
        "if os.path.isfile(audio_path):\n",
        "    Audio(filename=audio_path)\n",
        "else:\n",
        "    print(f\"File not found: {audio_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13914401-cad1-494a-b701-474e52829138",
      "metadata": {
        "id": "13914401-cad1-494a-b701-474e52829138"
      },
      "source": [
        "## üéâ Congratulations! üéâ You now have trained your first TTS model!\n",
        "Follow up with the next tutorials to learn more advanced material."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7",
      "metadata": {
        "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}